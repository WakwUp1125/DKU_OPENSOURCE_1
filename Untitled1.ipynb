{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlgfZVzIcp3JsFQwixLHf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WakwUp1125/DKU_OPENSOURCE_1/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "dLtmzX6ELipQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "601Qs-BkFOcI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "label_mapping = {\n",
        "    0: '집전체',\n",
        "    1: '지붕',\n",
        "    2: '집벽',\n",
        "    3: '문',\n",
        "    4: '창문',\n",
        "    5: '굴뚝',\n",
        "    6: '연기',\n",
        "    7: '울타리',\n",
        "    8: '길',\n",
        "    9: '연못',\n",
        "    10: '산',\n",
        "    11: '나무',\n",
        "    12: '꽃',\n",
        "    13: '잔디',\n",
        "    14: '태양',\n",
        "}\n",
        "\n",
        "def read_labels(label_file_path):\n",
        "    with open(label_file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    labels = [line.strip().split() for line in lines]\n",
        "    return labels\n",
        "\n",
        "def generate_caption(labels):\n",
        "    # 각 라벨에 대한 캡션 생성\n",
        "    captions = []\n",
        "    for label in labels:\n",
        "        label_number = int(label[0])\n",
        "        label_name = label_mapping.get(label_number, f\"라벨 {label_number}\")\n",
        "        coordinates = ', '.join(label[1:])\n",
        "        captions.append(f\"{label_name}: {coordinates}\")\n",
        "\n",
        "    # 이미지 전체에 대한 캡션 생성\n",
        "    image_caption = f\"Image: {image_name}\\n\" + \"\\n\".join(captions)\n",
        "    return image_caption\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 이미지와 레이블이 있는 폴더 경로 설정\n",
        "    image_folder_path = \"/images\"\n",
        "    label_folder_path = \"/labels\"\n",
        "\n",
        "    for image_name in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_name)\n",
        "        label_file_path = os.path.join(label_folder_path, os.path.splitext(image_name)[0] + '.txt')\n",
        "\n",
        "        if os.path.exists(label_file_path):\n",
        "            # 레이블 파일 읽기\n",
        "            labels = read_labels(label_file_path)\n",
        "\n",
        "            # 캡션 생성\n",
        "            image_caption = generate_caption(labels)\n",
        "            print(image_caption)\n",
        "            print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1번째 dataset / 집_10_여_08989.jpg\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 주어진 정보\n",
        "image_name = \"/content/test/images/집_10_여_08989.jpg\"\n",
        "captions_info = [\n",
        "    (\"집전체\", \"0.442578, 0.449609, 0.230469, 0.433594\"),\n",
        "    (\"지붕\", \"0.433203, 0.348047, 0.210156, 0.228906\"),\n",
        "    (\"집벽\", \"0.441406, 0.556641, 0.23125, 0.219531\"),\n",
        "    (\"문\", \"0.455078, 0.606641, 0.0820312, 0.0945312\"),\n",
        "    (\"창문\", \"0.376563, 0.511328, 0.0578125, 0.0460938\"),\n",
        "    (\"창문\", \"0.496484, 0.5, 0.0617188, 0.034375\"),\n",
        "    (\"굴뚝\", \"0.502734, 0.304297, 0.0570312, 0.194531\"),\n",
        "    (\"연기\", \"0.502734, 0.238281, 0.0570312, 0.0609375\"),\n",
        "    (\"울타리\", \"0.306641, 0.541406, 0.0789062, 0.164062\"),\n",
        "    (\"울타리\", \"0.607422, 0.534375, 0.157031, 0.167187\"),\n",
        "    (\"길\", \"0.770312, 0.736328, 0.459375, 0.274219\"),\n",
        "    (\"연못\", \"0.208984, 0.708594, 0.244531, 0.248438\"),\n",
        "    (\"산\", \"0.5, 0.235937, 1, 0.465625\"),\n",
        "    (\"나무\", \"0.866406, 0.542578, 0.267188, 0.432031\"),\n",
        "    (\"꽃\", \"0.323437, 0.640234, 0.0328125, 0.0367188\"),\n",
        "    (\"잔디\", \"0.342578, 0.666797, 0.0414062, 0.0273438\"),\n",
        "    (\"잔디\", \"0.582812, 0.599609, 0.0703125, 0.0226562\"),\n",
        "    (\"태양\", \"0.917969, 0.0875, 0.164062, 0.175\"),\n",
        "]\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(captions_info, columns=[\"Label\", \"Coordinates\"])\n",
        "df[\"Image Path\"] = image_name\n",
        "df[\"Caption\"] = \"START \" + df[\"Label\"] + \" \" + df[\"Coordinates\"] + \" END\"\n",
        "\n",
        "# 결과 출력\n",
        "print(df[[\"Image Path\", \"Caption\"]])\n",
        "\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv(\"image_caption_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "tVmPvVfLLFfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#두번쨰 dataset/ 집_12_남_11055.jpg\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 주어진 정보\n",
        "image_name = \"/content/test/images/집_12_남_11055.jpg\"\n",
        "captions_info = [\n",
        "    (\"집전체\",\"0.31875, 0.255078, 0.325, 0.332031\"),\n",
        "    (\"지붕\", \"0.316406, 0.212891, 0.320312, 0.139844\"),\n",
        "    (\"집벽\", \"0.317578, 0.333984, 0.272656, 0.172656\"),\n",
        "    (\"문\", \"0.274219, 0.353125, 0.0703125, 0.109375\"),\n",
        "    (\"창문\", \"0.380859, 0.312891, 0.0820312, 0.0664062\"),\n",
        "    (\"굴뚝\", \"0.347656, 0.115625, 0.3, 0.175\"),\n",
        "    (\"연기\", \"0.360938, 0.0804688, 0.276562, 0.101562\"),\n",
        "    (\"울타리\", \"0.693359, 0.317578, 0.430469, 0.102344\"),\n",
        "    (\"길\", \"0.16875, 0.682813, 0.278125, 0.582812\"),\n",
        "    (\"연못\", \"0.744922, 0.438281, 0.267969, 0.14375\"),\n",
        "    (\"산\", \"0.666406, 0.155078, 0.484375, 0.167969\"),\n",
        "    (\"나무\", \"0.423047, 0.659766, 0.230469, 0.463281\"),\n",
        "    (\"꽃\", \"0.111328, 0.460938, 0.122656, 0.151562\"),\n",
        "    (\"잔디\", \"0.664844, 0.589844, 0.0921875, 0.0421875\"),\n",
        "    (\"잔디\", \"0.672266, 0.684766, 0.0976562, 0.0398437\"),\n",
        "    (\"잔디\", \"0.785937, 0.644141, 0.101562, 0.0523438\"),\n",
        "    (\"태양\", \"0.105078, 0.130859, 0.158594, 0.160156\"),\n",
        "]\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(captions_info, columns=[\"Label\", \"Coordinates\"])\n",
        "df[\"Image Path\"] = image_name\n",
        "df[\"Caption\"] = \"START \" + df[\"Label\"] + \" \" + df[\"Coordinates\"] + \" END\"\n",
        "\n",
        "# 결과 출력\n",
        "print(df[[\"Image Path\", \"Caption\"]])\n",
        "\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv(\"image_caption_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "1O4nrkkELV5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3번째 dataset / 집_12_남_12779.jpg\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 주어진 정보\n",
        "image_name = \"/content/test/images/집_12_남_12779.jpg\"\n",
        "captions_info = [\n",
        "    (\"집전체\", \"0.190234, 0.575, 0.269531, 0.460938\"),\n",
        "    (\"지붕\", \"0.192969, 0.472656, 0.251563, 0.254688\"),\n",
        "    (\"집벽\", \"0.189453, 0.684375, 0.269531, 0.240625\"),\n",
        "    (\"문\", \"0.0859375, 0.747656, 0.059375, 0.1125\"),\n",
        "    (\"창문\", \"0.2375, 0.695703, 0.0828125, 0.0804688\"),\n",
        "    (\"굴뚝\", \"0.319141, 0.377344, 0.174219, 0.228125\"),\n",
        "    (\"연기\", \"0.332031, 0.314844, 0.146875, 0.103125\"),\n",
        "    (\"울타리\", \"0.0355469, 0.783203, 0.0710937, 0.0429688\"),\n",
        "    (\"울타리\", \"0.542578, 0.778516, 0.453906, 0.0664062\"),\n",
        "    (\"길\", \"0.499609, 0.623047, 0.999219, 0.569531\"),\n",
        "    (\"연못\", \"0.251953, 0.145313, 0.202344, 0.203125\"),\n",
        "    (\"산\", \"0.892969, 0.0929688, 0.164062, 0.185938\"),\n",
        "    (\"나무\", \"0.559766, 0.144531, 0.224219, 0.270313\"),\n",
        "    (\"꽃\", \"0.561719, 0.420703, 0.0328125, 0.0601563\"),\n",
        "    (\"꽃\", \"0.579688, 0.560156, 0.0375, 0.071875\"),\n",
        "    (\"꽃\", \"0.659766, 0.557031, 0.0289063, 0.0515625\"),\n",
        "    (\"잔디\", \"0.471094, 0.449219, 0.0265625, 0.065625\"),\n",
        "    (\"잔디\", \"0.691797, 0.455859, 0.0289063, 0.0523438\"),\n",
        "    (\"잔디\", \"0.39375, 0.595703, 0.025, 0.0414062\"),\n",
        "    (\"잔디\", \"0.568359, 0.657813, 0.0242188, 0.05625\"),\n",
        "    (\"태양\", \"0.0746094, 0.0925781, 0.139844, 0.172656\"),\n",
        "\n",
        "]\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(captions_info, columns=[\"Label\", \"Coordinates\"])\n",
        "df[\"Image Path\"] = image_name\n",
        "df[\"Caption\"] = \"START \" + df[\"Label\"] + \" \" + df[\"Coordinates\"] + \" END\"\n",
        "\n",
        "# 결과 출력\n",
        "print(df[[\"Image Path\", \"Caption\"]])\n",
        "\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv(\"image_caption_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "QsKrIWkCLZiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data.iloc[idx, 2]  # 2번 열은 image_path\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        caption = self.data.iloc[idx, 3]  # 3번 열은 caption\n",
        "\n",
        "        return img, caption\n",
        "\n",
        "# 이미지 변환을 위한 전처리 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "dataset = CustomDataset(\"image_caption_dataset.csv\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 간단한 이미지 캡셔닝 모델 정의 (이 모델은 토이 모델이며 실제로 사용하기에는 네트워크 구조 및 하이퍼파라미터를 조절해야 합니다.)\n",
        "class SimpleImageCaptioningModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(SimpleImageCaptioningModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleImageCaptioningModel(vocab_size=1000, embed_size=256, hidden_size=512)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 예제 (조절이 필요한 부분이 많으며, 실제 데이터셋 및 모델에 맞게 수정해야 합니다.)\n",
        "for epoch in range(10):\n",
        "    for images, captions in dataloader:\n",
        "        # 이미지를 모델 입력에 맞게 변환\n",
        "        images = images.view(images.size(0), -1)\n",
        "\n",
        "        # 모델 출력 및 손실 계산\n",
        "        outputs = model(images)\n",
        "        targets = captions.view(-1)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # 역전파 및 가중치 갱신\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "7bYoi_-LLdOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.nn import functional as F\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import pandas as pd\n",
        "\n",
        "# 이미지 전처리 및 모델 로드\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# 이미지 캡션 생성\n",
        "def generate_caption(model, image_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(image_tensor)\n",
        "\n",
        "    # 여기에서는 모델이 반환하는 예측 중 일부를 사용하여 캡션을 생성합니다.\n",
        "    # 적절한 방법으로 모델의 출력을 처리해야 할 수 있습니다.\n",
        "    caption = f\"Generated caption: {prediction}\"\n",
        "    return caption\n",
        "\n",
        "# CSV 파일에서 이미지 경로와 캡션 읽기\n",
        "csv_file_path = \"/content/image_caption_dataset.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "image_paths = df['Image Path']\n",
        "captions = df['Caption']\n",
        "\n",
        "# 모델 로드\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# 예시로 이미지 경로 설정\n",
        "image_path = \"/content/test/images/집_10_여_08989.jpg\"\n",
        "image_tensor = preprocess_image(image_path)\n",
        "caption = generate_caption(model, image_tensor)\n",
        "print(caption)"
      ],
      "metadata": {
        "id": "5EPMGMWeLrLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption_from_prediction(prediction, threshold=0.5):\n",
        "    boxes = prediction['boxes']\n",
        "    labels = prediction['labels']\n",
        "    scores = prediction['scores']\n",
        "\n",
        "    # 점수가 임계값보다 높은 객체만 선택\n",
        "    selected_indices = scores >= threshold\n",
        "    boxes = boxes[selected_indices]\n",
        "    labels = labels[selected_indices]\n",
        "    scores = scores[selected_indices]\n",
        "\n",
        "    if len(boxes) == 0:\n",
        "        return \"No objects detected.\"\n",
        "\n",
        "    highest_score_index = scores.argmax().item()\n",
        "    box = boxes[highest_score_index]\n",
        "    label = labels[highest_score_index]\n",
        "    score = scores[highest_score_index]\n",
        "\n",
        "    caption = f\"Detected object: {label}, Score: {score:.2f}, Bounding Box: {box}\"\n",
        "    return caption\n",
        "\n",
        "# 이미지 경로 설정 (여러분이 사용하는 이미지 경로로 수정해야 합니다)\n",
        "image_path = \"/content/drive/MyDrive/오픈소스Ai/나무_10_남_00431.jpg\"\n",
        "image_tensor = preprocess_image(image_path)\n",
        "caption = generate_caption(model, image_tensor)\n",
        "print(caption)"
      ],
      "metadata": {
        "id": "fdAmC58eLvBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_description(prediction):\n",
        "    if not prediction['boxes']:\n",
        "        return \"No object detected.\"\n",
        "\n",
        "    # 바운딩 박스 중앙 좌표 계산\n",
        "    box = prediction['boxes'][0]\n",
        "    center_x = (box[0] + box[2]) / 2\n",
        "    center_y = (box[1] + box[3]) / 2\n",
        "\n",
        "    # 중앙 좌표를 기반으로 이미지에 대한 설명 생성\n",
        "    description = f\"The object is located at ({center_x}, {center_y}).\"\n",
        "    return description\n",
        "\n",
        "# 예측 결과\n",
        "prediction_result = {'boxes': torch.tensor([[111.2635, 44.4517, 1116.6461, 1182.4984]]),\n",
        "                     'labels': torch.tensor([64]),  # 여러 레이블이라면 리스트로 수정\n",
        "                     'scores': torch.tensor([0.0577])}\n",
        "\n",
        "# 이미지에 대한 설명 생성\n",
        "description = generate_description(prediction_result)\n",
        "print(description)"
      ],
      "metadata": {
        "id": "Vxgc2jTHLxtX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}